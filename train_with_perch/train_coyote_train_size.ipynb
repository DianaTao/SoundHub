{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/3533495058.py:10: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random \n",
    "from glob import glob\n",
    "import sklearn\n",
    "\n",
    "from tqdm.autonotebook import tqdm\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score\n",
    "from pathlib import Path\n",
    "\n",
    "#set up plotting\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['figure.figsize']=[15,5] #for large visuals\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# opensoundscape transfer learning tools\n",
    "from opensoundscape.ml.shallow_classifier import MLPClassifier, quick_fit, fit_classifier_on_embeddings\n",
    "import os\n",
    "from pathlib import Path\n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "random.seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved for training size train_size_150: /Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/labels_trains_train_size_150.csv\n",
      "DataFrame saved for training size train_size_25: /Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/labels_trains_train_size_25.csv\n",
      "DataFrame saved for training size train_size_175: /Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/labels_trains_train_size_175.csv\n",
      "DataFrame saved for training size train_size_75: /Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/labels_trains_train_size_75.csv\n",
      "DataFrame saved for training size train_size_100: /Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/labels_trains_train_size_100.csv\n",
      "DataFrame saved for training size train_size_200: /Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/labels_trains_train_size_200.csv\n",
      "DataFrame saved for training size train_size_50: /Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/labels_trains_train_size_50.csv\n",
      "DataFrame saved for training size train_size_125: /Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/labels_trains_train_size_125.csv\n",
      "\n",
      "DataFrame for training size train_size_150:\n",
      "                                                                        A\n",
      "file                                               start_time end_time   \n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "\n",
      "DataFrame for training size train_size_25:\n",
      "                                                                        A\n",
      "file                                               start_time end_time   \n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "\n",
      "DataFrame for training size train_size_175:\n",
      "                                                                        A\n",
      "file                                               start_time end_time   \n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "\n",
      "DataFrame for training size train_size_75:\n",
      "                                                                        A\n",
      "file                                               start_time end_time   \n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "\n",
      "DataFrame for training size train_size_100:\n",
      "                                                                        A\n",
      "file                                               start_time end_time   \n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "\n",
      "DataFrame for training size train_size_200:\n",
      "                                                                        A\n",
      "file                                               start_time end_time   \n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "\n",
      "DataFrame for training size train_size_50:\n",
      "                                                                        A\n",
      "file                                               start_time end_time   \n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "\n",
      "DataFrame for training size train_size_125:\n",
      "                                                                        A\n",
      "file                                               start_time end_time   \n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Define dataset path\n",
    "dataset_path = Path(\"/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/\")\n",
    "train_path = dataset_path / \"train_5sec\"\n",
    "\n",
    "# Function to traverse directories and map file information to labels\n",
    "def traverse_and_map(directory, label):\n",
    "    audio_files = []\n",
    "    labels = []\n",
    "    start_times = []\n",
    "    end_times = []\n",
    "    \n",
    "    if not directory.exists():\n",
    "        print(f\"Directory does not exist: {directory}\")\n",
    "        return pd.DataFrame()  # Return empty DataFrame if directory doesn't exist\n",
    "    \n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith(\".mp3\"):\n",
    "                # Prepend full dataset path to the file path\n",
    "                audio_path = dataset_path / Path(root).relative_to(dataset_path) / file\n",
    "                audio_files.append(str(audio_path))\n",
    "                labels.append(label)\n",
    "                start_times.append(0.0)  # Fixed start time\n",
    "                end_times.append(5.0)   # Fixed end time\n",
    "\n",
    "    # Create DataFrame for the current directory\n",
    "    data = {\n",
    "        \"file\": audio_files,\n",
    "        \"start_time\": start_times,\n",
    "        \"end_time\": end_times,\n",
    "        \"A\": labels\n",
    "    }\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Initialize a dictionary to hold DataFrames for each training size\n",
    "labels_trains = {}\n",
    "\n",
    "# Iterate over each train size folder\n",
    "if train_path.exists():\n",
    "    for train_size_dir in train_path.iterdir():\n",
    "        if train_size_dir.is_dir():  # Ensure it's a directory\n",
    "            training_size = train_size_dir.name  # Get the name of the training size directory\n",
    "\n",
    "            # Process `pos` and `neg` subdirectories\n",
    "            pos_dir = train_size_dir / \"pos\"\n",
    "            neg_dir = train_size_dir / \"neg\"\n",
    "            df_pos = traverse_and_map(pos_dir, 1)  # 1 for \"pos\" files\n",
    "            df_neg = traverse_and_map(neg_dir, 0)  # 0 for \"negative\" files\n",
    "\n",
    "            # Combine the DataFrames for `pos` and `neg`\n",
    "            combined_df = pd.concat([df_pos, df_neg], ignore_index=True)\n",
    "\n",
    "            # Set MultiIndex with 'file', 'start_time', and 'end_time'\n",
    "            combined_df.set_index([\"file\", \"start_time\", \"end_time\"], inplace=True)\n",
    "\n",
    "            # Rename the only column to \"A\"\n",
    "            combined_df.columns = ['A']\n",
    "\n",
    "            # Store the DataFrame in the dictionary\n",
    "            labels_trains[training_size] = combined_df\n",
    "\n",
    "            # Optionally, save each DataFrame to a CSV file\n",
    "            output_path = dataset_path / f\"labels_trains_{training_size}.csv\"\n",
    "            combined_df.to_csv(output_path)\n",
    "            print(f\"DataFrame saved for training size {training_size}: {output_path}\")\n",
    "else:\n",
    "    print(f\"Train path does not exist: {train_path}\")\n",
    "\n",
    "# Display the DataFrames for verification\n",
    "for training_size, df in labels_trains.items():\n",
    "    print(f\"\\nDataFrame for training size {training_size}:\")\n",
    "    print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing data for training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>file</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/train_5sec/train_size_150/pos/t-11031961_309_9sec_2_a.mp3</th>\n",
       "      <th>0.0</th>\n",
       "      <th>5.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/train_5sec/train_size_150/pos/t-11031961_194_9sec_1_a.mp3</th>\n",
       "      <th>0.0</th>\n",
       "      <th>5.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/train_5sec/train_size_150/pos/t-11031961_156_9sec_2_a.mp3</th>\n",
       "      <th>0.0</th>\n",
       "      <th>5.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/train_5sec/train_size_150/pos/t-11031961_193_9sec_1_a.mp3</th>\n",
       "      <th>0.0</th>\n",
       "      <th>5.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/train_5sec/train_size_150/pos/t-11031961_310_9sec_3_a.mp3</th>\n",
       "      <th>0.0</th>\n",
       "      <th>5.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/train_5sec/train_size_150/pos/t-11031961_138_9sec_1_f.mp3</th>\n",
       "      <th>0.0</th>\n",
       "      <th>5.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/train_5sec/train_size_150/pos/t-11031961_132_9sec_2_a.mp3</th>\n",
       "      <th>0.0</th>\n",
       "      <th>5.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/train_5sec/train_size_150/pos/t-11031961_186_9sec_1_b.mp3</th>\n",
       "      <th>0.0</th>\n",
       "      <th>5.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/train_5sec/train_size_150/pos/t-11031961_179_9sec_1_b.mp3</th>\n",
       "      <th>0.0</th>\n",
       "      <th>5.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/train_5sec/train_size_150/pos/t-11031961_135_9sec_2_a.mp3</th>\n",
       "      <th>0.0</th>\n",
       "      <th>5.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/train_5sec/train_size_150/pos/t-11031961_204_9sec_1_c.mp3</th>\n",
       "      <th>0.0</th>\n",
       "      <th>5.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/train_5sec/train_size_150/pos/t-11031961_216_9sec_1_b.mp3</th>\n",
       "      <th>0.0</th>\n",
       "      <th>5.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/train_5sec/train_size_150/pos/t-11031961_26_9sec_1_a.mp3</th>\n",
       "      <th>0.0</th>\n",
       "      <th>5.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/train_5sec/train_size_150/pos/t-11031961_310_9sec_1_a.mp3</th>\n",
       "      <th>0.0</th>\n",
       "      <th>5.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/train_5sec/train_size_150/pos/t-11031961_216_9sec_1_c.mp3</th>\n",
       "      <th>0.0</th>\n",
       "      <th>5.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/train_5sec/train_size_150/pos/t-11031961_166_9sec_4_a.mp3</th>\n",
       "      <th>0.0</th>\n",
       "      <th>5.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/train_5sec/train_size_150/pos/t-11031961_186_9sec_1_c.mp3</th>\n",
       "      <th>0.0</th>\n",
       "      <th>5.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/train_5sec/train_size_150/pos/t-11031961_192_9sec_1_a.mp3</th>\n",
       "      <th>0.0</th>\n",
       "      <th>5.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/train_5sec/train_size_150/pos/t-11031961_195_9sec_1_a.mp3</th>\n",
       "      <th>0.0</th>\n",
       "      <th>5.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/train_5sec/train_size_150/pos/t-11031961_320_9sec_1_a.mp3</th>\n",
       "      <th>0.0</th>\n",
       "      <th>5.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                        A\n",
       "file                                               start_time end_time   \n",
       "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
       "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
       "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
       "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
       "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
       "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
       "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
       "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
       "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
       "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
       "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
       "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
       "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
       "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
       "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
       "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
       "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
       "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
       "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
       "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_trains['train_size_150'].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare audio Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Train shallow classifier on Perch embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/yifeitao/.cache/torch/hub/kitzeslab_bioacoustics-model-zoo_main\n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('kitzeslab/bioacoustics-model-zoo','rana_sierrae_cnn',trust_repo=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Generate embeddings on the training and validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training size 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ae62091bdf04759a113b833d730e8ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.9996875 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999770833333334 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999583333333334 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999416666666667 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999708333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999916666666667 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999729166666667 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.9998125 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.9995416666666666 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n"
     ]
    }
   ],
   "source": [
    "emb_train_25 = model.embed(labels_trains['train_size_25'], return_dfs=False, batch_size=32, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed dataset saved to /Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/processed_test_dataset_5sec.csv\n",
      "Audio clips saved to /Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips\n",
      "                                                                        A\n",
      "file                                               start_time end_time   \n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       0\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       0\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       0\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:20: ResourceWarning: unclosed file <_io.BufferedReader name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/test_dataset_5sec.wav'>\n",
      "  audio = AudioSegment.from_file(audio_file_path)\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_327_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_8_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_81_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_212_9sec_1_c.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_159_9sec_1_b.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_175_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_145_9sec_2_c.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_378_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_198_9sec_1_c.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_136_9sec_2_b.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_168_9sec_1_b.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_172_9sec_2_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_286_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_217_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_259_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_205_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_237_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_357_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_217_9sec_1_d.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_156_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_299_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_99_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_134_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_309_9sec_3_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_105_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_204_9sec_1_b.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_135_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_86_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_310_9sec_2_b.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_392_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_7_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_210_9sec_1_b.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_298_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_171_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_250_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_183_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_236_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_398_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_125_9sec_1_c.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_217_9sec_1_c.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_197_9sec_1_c.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_313_9sec_2_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_145_9sec_2_b.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_350_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_206_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_152_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_29_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_126_9sec_2_b.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_342_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_160_9sec_1_b.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_199_9sec_2_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_178_9sec_2_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_185_9sec_3_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_175_9sec_1_b.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_191_9sec_2_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_83_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_210_9sec_1_c.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_289_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_176_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_98_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_281_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_120_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_6_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_132_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_173_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_361_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_163_9sec_1_b.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_384_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_224_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_370_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_254_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_177_9sec_1_c.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_282_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_165_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_150_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_380_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_264_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_185_9sec_2_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_85_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_21_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_233_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_222_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_154_9sec_2_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_134_9sec_2_b.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_174_9sec_2_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_326_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_320_9sec_2_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_159_9sec_2_b.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_143_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_391_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_93_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_80_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_23_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_72_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_216_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_257_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_58_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_192_9sec_2_d.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_129_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/240471425.py:39: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips/t-11031961_109_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n"
     ]
    }
   ],
   "source": [
    "csv_path = Path(\"/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/test_dataset_5sec.csv\")\n",
    "audio_file_path = Path(\"/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/test_dataset_5sec.wav\")\n",
    "output_folder = Path(\"/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/clips\")\n",
    "output_csv_dir = Path(\"/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/coyotes_5sec/test_5sec/\")\n",
    "output_csv = output_csv_dir / \"processed_test_dataset_5sec.csv\"\n",
    "\n",
    "# Ensure the output directories exist\n",
    "output_folder.mkdir(parents=True, exist_ok=True)\n",
    "output_csv_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Read the CSV file\n",
    "df_csv = pd.read_csv(csv_path)\n",
    "\n",
    "# Determine label based on conditions\n",
    "df_csv[\"A\"] = df_csv.apply(\n",
    "    lambda row: 1 if row[\"label\"] == 1 and row[\"Annotation\"] == \"COYOTE\" else 0, axis=1\n",
    ")\n",
    "\n",
    "# Load the audio file\n",
    "audio = AudioSegment.from_file(audio_file_path)\n",
    "\n",
    "# Initialize lists for DataFrame creation\n",
    "file_paths = []\n",
    "start_times = []\n",
    "end_times = []\n",
    "labels = []\n",
    "\n",
    "# Partition the audio file into 5-second clips based on CSV\n",
    "for index, row in df_csv.iterrows():\n",
    "    start_time = index * 5 * 1000  # in milliseconds\n",
    "    end_time = start_time + 5 * 1000  # 5 seconds later\n",
    "\n",
    "    # Extract clip\n",
    "    clip = audio[start_time:end_time]\n",
    "\n",
    "    # Save clip to the output folder\n",
    "    filename = row[\"filename\"]\n",
    "    clip_path = output_folder / filename\n",
    "    clip.export(clip_path, format=\"wav\")\n",
    "\n",
    "    # Add details to lists\n",
    "    file_paths.append(str(clip_path))\n",
    "    start_times.append(0.0)  \n",
    "    end_times.append(5.0)  \n",
    "    labels.append(row[\"A\"])\n",
    "\n",
    "# Create the DataFrame\n",
    "df_processed = pd.DataFrame({\n",
    "    \"file\": file_paths,\n",
    "    \"start_time\": start_times,\n",
    "    \"end_time\": end_times,\n",
    "    \"A\": labels\n",
    "})\n",
    "df_processed.set_index([\"file\", \"start_time\", \"end_time\"], inplace=True)\n",
    "df_processed.columns = ['A']\n",
    "# Save the DataFrame to a CSV file\n",
    "df_processed.to_csv(output_csv, index=False)\n",
    "\n",
    "print(f\"Processed dataset saved to {output_csv}\")\n",
    "print(f\"Audio clips saved to {output_folder}\")\n",
    "print(df_processed.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_val = df_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df7abdd47a5f41b192d2031e815fe66a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.987 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n"
     ]
    }
   ],
   "source": [
    "emb_val = model.embed(labels_val, return_dfs=False, batch_size=32, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape of emb_train: torch.Size([50, 512])\n",
      "Reshaped emb_train_25: torch.Size([50, 1, 32, 16])\n",
      "Reshaped emb_val: torch.Size([100, 1, 32, 16])\n"
     ]
    }
   ],
   "source": [
    "emb_train_25 = torch.tensor(emb_train_25, dtype=torch.float32)\n",
    "emb_val = torch.tensor(emb_val, dtype=torch.float32)\n",
    "\n",
    "# Check the shape of the embeddings\n",
    "print(f\"Original shape of emb_train: {emb_train_25.shape}\")\n",
    "\n",
    "# Reshape embeddings to [batch_size, channels, height, width]\n",
    "height, width = 32, 16  # Ensure height * width = 512\n",
    "emb_train_25 = emb_train_25.view(emb_train_25.shape[0], 1, height, width)\n",
    "emb_val = emb_val.view(emb_val.shape[0], 1, height, width)\n",
    "\n",
    "# Verify the reshaped embeddings\n",
    "print(f\"Reshaped emb_train_25: {emb_train_25.shape}\")\n",
    "print(f\"Reshaped emb_val: {emb_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "if isinstance(model.network, nn.Sequential):\n",
    "    first_layer = model.network[0]\n",
    "    if isinstance(first_layer, nn.Conv2d):\n",
    "        model.network[0] = nn.Conv2d(\n",
    "            in_channels=1,\n",
    "            out_channels=first_layer.out_channels,\n",
    "            kernel_size=first_layer.kernel_size,\n",
    "            stride=first_layer.stride,\n",
    "            padding=first_layer.padding\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_train_25 = emb_train_25.repeat(1, 3, 1, 1)  # Duplicate to 3 channels\n",
    "emb_val = emb_val.repeat(1, 3, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "model.network.fc = nn.Linear(in_features=model.network.fc.in_features, out_features=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/ml/shallow_classifier.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_features = torch.tensor(train_features, dtype=torch.float32, device=device)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/ml/shallow_classifier.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  validation_features = torch.tensor(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/1000, Loss: 4.696367614087649e-05, Val Loss: 0.45042601227760315\n",
      "val AU ROC: 0.870\n",
      "val MAP: 0.870\n",
      "Epoch 200/1000, Loss: 3.331392872496508e-05, Val Loss: 0.4591938257217407\n",
      "val AU ROC: 0.871\n",
      "val MAP: 0.871\n",
      "Epoch 300/1000, Loss: 2.6388528567622416e-05, Val Loss: 0.4653064012527466\n",
      "val AU ROC: 0.871\n",
      "val MAP: 0.871\n",
      "Epoch 400/1000, Loss: 2.146065526176244e-05, Val Loss: 0.4699302315711975\n",
      "val AU ROC: 0.870\n",
      "val MAP: 0.870\n",
      "Epoch 500/1000, Loss: 1.785276981536299e-05, Val Loss: 0.47741538286209106\n",
      "val AU ROC: 0.869\n",
      "val MAP: 0.869\n",
      "Epoch 600/1000, Loss: 1.5054414689075202e-05, Val Loss: 0.48703229427337646\n",
      "val AU ROC: 0.870\n",
      "val MAP: 0.870\n",
      "Epoch 700/1000, Loss: 1.282439916394651e-05, Val Loss: 0.49523448944091797\n",
      "val AU ROC: 0.869\n",
      "val MAP: 0.869\n",
      "Epoch 800/1000, Loss: 1.1113759683212265e-05, Val Loss: 0.5026193857192993\n",
      "val AU ROC: 0.870\n",
      "val MAP: 0.870\n",
      "Epoch 900/1000, Loss: 9.67748201219365e-06, Val Loss: 0.5096595883369446\n",
      "val AU ROC: 0.870\n",
      "val MAP: 0.870\n",
      "Epoch 1000/1000, Loss: 8.46039711177582e-06, Val Loss: 0.51563960313797\n",
      "val AU ROC: 0.869\n",
      "val MAP: 0.869\n",
      "Training complete\n"
     ]
    }
   ],
   "source": [
    "quick_fit(model.network, emb_train_25, labels_trains['train_size_25'].values, emb_val, labels_val.values, steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_3947/1842857064.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  preds = model.network(torch.tensor(emb_val).float()).detach().numpy()\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/matplotlib_inline/config.py:68: DeprecationWarning: InlineBackend._figure_format_changed is deprecated in traitlets 4.1: use @observe and @unobserve instead.\n",
      "  def _figure_format_changed(self, name, old, new):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9468000000000001"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 428,
       "width": 1209
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make predictions by passing the embeddings through the classifier\n",
    "preds = model.network(torch.tensor(emb_val).float()).detach().numpy()\n",
    "\n",
    "# plot histogram of scores for positive and negative clips\n",
    "plt.hist(preds[labels_val==True],bins=20,alpha=0.5,label='positives')\n",
    "plt.hist(preds[labels_val==False],bins=20,alpha=0.5,label='negatives')\n",
    "plt.legend()\n",
    "\n",
    "# calculate the area under the ROC score\n",
    "roc_auc_score_25 = roc_auc_score(labels_val.values,preds,average=None)\n",
    "roc_auc_score_25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training size 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_train_50 = model.embed(labels_trains['train_size_50'], return_dfs=False, batch_size=32, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_train_50 = torch.tensor(emb_train_50, dtype=torch.float32)\n",
    "\n",
    "# Check the shape of the embeddings\n",
    "print(f\"Original shape of emb_train: {emb_train_50.shape}\")\n",
    "\n",
    "# Reshape embeddings to [batch_size, channels, height, width]\n",
    "height, width = 32, 16  # Ensure height * width = 512\n",
    "emb_train_50 = emb_train_50.view(emb_train_50.shape[0], 1, height, width)\n",
    "\n",
    "# Verify the reshaped embeddings\n",
    "print(f\"Reshaped emb_train_50: {emb_train_50.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_train_50 = emb_train_50.repeat(1, 3, 1, 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_fit(model.network, emb_train_50, labels_trains['train_size_50'].values, emb_val, labels_val.values, steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions by passing the embeddings through the classifier\n",
    "preds = model.network(torch.tensor(emb_val).float()).detach().numpy()\n",
    "\n",
    "# plot histogram of scores for positive and negative clips\n",
    "plt.hist(preds[labels_val==True],bins=20,alpha=0.5,label='positives')\n",
    "plt.hist(preds[labels_val==False],bins=20,alpha=0.5,label='negatives')\n",
    "plt.legend()\n",
    "\n",
    "# calculate the area under the ROC score\n",
    "roc_auc_score_50 = roc_auc_score(labels_val.values,preds,average=None)\n",
    "roc_auc_score_50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training size 75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_train_75 = model.embed(labels_trains['train_size_75'], return_dfs=False, batch_size=32, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_train_75 = torch.tensor(emb_train_75, dtype=torch.float32)\n",
    "\n",
    "# Check the shape of the embeddings\n",
    "print(f\"Original shape of emb_train: {emb_train_75.shape}\")\n",
    "\n",
    "# Reshape embeddings to [batch_size, channels, height, width]\n",
    "height, width = 32, 16  # Ensure height * width = 512\n",
    "emb_train_75 = emb_train_75.view(emb_train_75.shape[0], 1, height, width)\n",
    "\n",
    "\n",
    "# Verify the reshaped embeddings\n",
    "print(f\"Reshaped emb_train_75: {emb_train_75.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_train_75 = emb_train_75.repeat(1, 3, 1, 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_fit(model.network, emb_train_75, labels_trains['train_size_75'].values, emb_val, labels_val.values, steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions by passing the embeddings through the classifier\n",
    "preds = model.network(torch.tensor(emb_val).float()).detach().numpy()\n",
    "\n",
    "# plot histogram of scores for positive and negative clips\n",
    "plt.hist(preds[labels_val==True],bins=20,alpha=0.5,label='positives')\n",
    "plt.hist(preds[labels_val==False],bins=20,alpha=0.5,label='negatives')\n",
    "plt.legend()\n",
    "\n",
    "# calculate the area under the ROC score\n",
    "roc_auc_score(labels_val.values,preds,average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score_75 = 0.571288888888"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training size 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_train_100 = model.embed(labels_trains['train_size_100'], return_dfs=False, batch_size=32, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_train_100 = torch.tensor(emb_train_100, dtype=torch.float32)\n",
    "# Check the shape of the embeddings\n",
    "print(f\"Original shape of emb_train: {emb_train_100.shape}\")\n",
    "\n",
    "# Reshape embeddings to [batch_size, channels, height, width]\n",
    "height, width = 32, 16  # Ensure height * width = 512\n",
    "emb_train_100 = emb_train_100.view(emb_train_100.shape[0], 1, height, width)\n",
    "\n",
    "# Verify the reshaped embeddings\n",
    "print(f\"Reshaped emb_train_100: {emb_train_100.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_train_100 = emb_train_100.repeat(1, 3, 1, 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_fit(model.network, emb_train_100, labels_trains['train_size_100'].values, emb_val, labels_val.values, steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions by passing the embeddings through the classifier\n",
    "preds = model.network(torch.tensor(emb_val).float()).detach().numpy()\n",
    "\n",
    "# plot histogram of scores for positive and negative clips\n",
    "plt.hist(preds[labels_val==True],bins=20,alpha=0.5,label='positives')\n",
    "plt.hist(preds[labels_val==False],bins=20,alpha=0.5,label='negatives')\n",
    "plt.legend()\n",
    "\n",
    "# calculate the area under the ROC score\n",
    "roc_auc_score_100 = roc_auc_score(labels_val.values,preds,average=None)\n",
    "roc_auc_score_100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training size 125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_train_125 = model.embed(labels_trains['train_size_125'], return_dfs=False, batch_size=32, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_train_125 = torch.tensor(emb_train_125, dtype=torch.float32)\n",
    "# Check the shape of the embeddings\n",
    "print(f\"Original shape of emb_train: {emb_train_125.shape}\")\n",
    "\n",
    "height, width = 32, 16  # Ensure height * width = 512\n",
    "emb_train_125 = emb_train_125.view(emb_train_125.shape[0], 1, height, width)\n",
    "\n",
    "# Verify the reshaped embeddings\n",
    "print(f\"Reshaped emb_train_100: {emb_train_125.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_train_125 = emb_train_125.repeat(1, 3, 1, 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_fit(model.network, emb_train_125, labels_trains['train_size_125'].values, emb_val, labels_val.values, steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions by passing the embeddings through the classifier\n",
    "preds = model.network(torch.tensor(emb_val).float()).detach().numpy()\n",
    "\n",
    "# plot histogram of scores for positive and negative clips\n",
    "plt.hist(preds[labels_val==True],bins=20,alpha=0.5,label='positives')\n",
    "plt.hist(preds[labels_val==False],bins=20,alpha=0.5,label='negatives')\n",
    "plt.legend()\n",
    "\n",
    "# calculate the area under the ROC score\n",
    "roc_auc_score_125 = roc_auc_score(labels_val.values,preds,average=None)\n",
    "roc_auc_score_125"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training size 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_train_150 = model.embed(labels_trains['train_size_150'], return_dfs=False, batch_size=32, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_train_150 = torch.tensor(emb_train_150, dtype=torch.float32)\n",
    "# Check the shape of the embeddings\n",
    "print(f\"Original shape of emb_train: {emb_train_150.shape}\")\n",
    "\n",
    "# Reshape embeddings to [batch_size, channels, height, width]\n",
    "height, width = 32, 16  # Ensure height * width = 512\n",
    "emb_train_150 = emb_train_150.view(emb_train_150.shape[0], 1, height, width)\n",
    "\n",
    "# Verify the reshaped embeddings\n",
    "print(f\"Reshaped emb_train_150: {emb_train_150.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_train_150 = emb_train_150.repeat(1, 3, 1, 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_fit(model.network, emb_train_150, labels_trains['train_size_150'].values, emb_val, labels_val.values, steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions by passing the embeddings through the classifier\n",
    "preds = model.network(torch.tensor(emb_val).float()).detach().numpy()\n",
    "\n",
    "# plot histogram of scores for positive and negative clips\n",
    "plt.hist(preds[labels_val==True],bins=20,alpha=0.5,label='positives')\n",
    "plt.hist(preds[labels_val==False],bins=20,alpha=0.5,label='negatives')\n",
    "plt.legend()\n",
    "\n",
    "# calculate the area under the ROC score\n",
    "roc_auc_score_150 = roc_auc_score(labels_val.values,preds,average=None)\n",
    "roc_auc_score_150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training size 175"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_train_175 = model.embed(labels_trains['train_size_175'], return_dfs=False, batch_size=32, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_train_175 = torch.tensor(emb_train_175, dtype=torch.float32)\n",
    "# Check the shape of the embeddings\n",
    "print(f\"Original shape of emb_train: {emb_train_175.shape}\")\n",
    "\n",
    "# Reshape embeddings to [batch_size, channels, height, width]\n",
    "height, width = 32, 16  # Ensure height * width = 512\n",
    "emb_train_175 = emb_train_175.view(emb_train_175.shape[0], 1, height, width)\n",
    "\n",
    "\n",
    "# Verify the reshaped embeddings\n",
    "print(f\"Reshaped emb_train_175: {emb_train_175.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_train_175 = emb_train_175.repeat(1, 3, 1, 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_fit(model.network, emb_train_175, labels_trains['train_size_175'].values, emb_val, labels_val.values, steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.network(torch.tensor(emb_val).float()).detach().numpy()\n",
    "\n",
    "# plot histogram of scores for positive and negative clips\n",
    "plt.hist(preds[labels_val==True],bins=20,alpha=0.5,label='positives')\n",
    "plt.hist(preds[labels_val==False],bins=20,alpha=0.5,label='negatives')\n",
    "plt.legend()\n",
    "\n",
    "# calculate the area under the ROC score\n",
    "roc_auc_score_175 = roc_auc_score(labels_val.values,preds,average=None)\n",
    "roc_auc_score_175"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training size 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.hub.load('kitzeslab/bioacoustics-model-zoo','rana_sierrae_cnn',trust_repo=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_val = model.embed(labels_val, return_dfs=False, batch_size=32, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_train_200 = model.embed(labels_trains['train_size_200'], return_dfs=False, batch_size=32, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_train_200 = torch.tensor(emb_train_200, dtype=torch.float32)\n",
    "emb_val = torch.tensor(emb_val, dtype=torch.float32)\n",
    "\n",
    "# Check the shape of the embeddings\n",
    "print(f\"Original shape of emb_train: {emb_train_200.shape}\")\n",
    "\n",
    "# Reshape embeddings to [batch_size, channels, height, width]\n",
    "height, width = 32, 16  # Ensure height * width = 512\n",
    "emb_train_200 = emb_train_200.view(emb_train_200.shape[0], 1, height, width)\n",
    "emb_val = emb_val.view(emb_val.shape[0], 1, height, width)\n",
    "\n",
    "# Verify the reshaped embeddings\n",
    "print(f\"Reshaped emb_train_200: {emb_train_200.shape}\")\n",
    "print(f\"Reshaped emb_val: {emb_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(model.network, nn.Sequential):\n",
    "    first_layer = model.network[0]\n",
    "    if isinstance(first_layer, nn.Conv2d):\n",
    "        model.network[0] = nn.Conv2d(\n",
    "            in_channels=1,\n",
    "            out_channels=first_layer.out_channels,\n",
    "            kernel_size=first_layer.kernel_size,\n",
    "            stride=first_layer.stride,\n",
    "            padding=first_layer.padding\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_train_200 = emb_train_200.repeat(1, 3, 1, 1) \n",
    "emb_val = emb_val.repeat(1, 3, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.network.fc = nn.Linear(in_features=model.network.fc.in_features, out_features=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_fit(model.network, emb_train_200, labels_trains['train_size_200'].values, emb_val, labels_val.values, steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.network(torch.tensor(emb_val).float()).detach().numpy()\n",
    "\n",
    "# plot histogram of scores for positive and negative clips\n",
    "plt.hist(preds[labels_val==True],bins=20,alpha=0.5,label='positives')\n",
    "plt.hist(preds[labels_val==False],bins=20,alpha=0.5,label='negatives')\n",
    "plt.legend()\n",
    "\n",
    "# calculate the area under the ROC score\n",
    "roc_auc_score_200 = roc_auc_score(labels_val.values,preds,average=None)\n",
    "roc_auc_score_200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training size 225"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.hub.load('kitzeslab/bioacoustics-model-zoo','rana_sierrae_cnn',trust_repo=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_val = model.embed(labels_val, return_dfs=False, batch_size=32, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_train_225 = model.embed(labels_trains['train_size_225'], return_dfs=False, batch_size=32, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_train_225 = torch.tensor(emb_train_225, dtype=torch.float32)\n",
    "emb_val = torch.tensor(emb_val, dtype=torch.float32)\n",
    "\n",
    "# Check the shape of the embeddings\n",
    "print(f\"Original shape of emb_train: {emb_train_225.shape}\")\n",
    "\n",
    "# Reshape embeddings to [batch_size, channels, height, width]\n",
    "height, width = 32, 16  # Ensure height * width = 512\n",
    "emb_train_225 = emb_train_225.view(emb_train_225.shape[0], 1, height, width)\n",
    "emb_val = emb_val.view(emb_val.shape[0], 1, height, width)\n",
    "\n",
    "# Verify the reshaped embeddings\n",
    "print(f\"Reshaped emb_train_225: {emb_train_225.shape}\")\n",
    "print(f\"Reshaped emb_val: {emb_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(model.network, nn.Sequential):\n",
    "    first_layer = model.network[0]\n",
    "    if isinstance(first_layer, nn.Conv2d):\n",
    "        model.network[0] = nn.Conv2d(\n",
    "            in_channels=1,\n",
    "            out_channels=first_layer.out_channels,\n",
    "            kernel_size=first_layer.kernel_size,\n",
    "            stride=first_layer.stride,\n",
    "            padding=first_layer.padding\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_train_225 = emb_train_225.repeat(1, 3, 1, 1) \n",
    "emb_val = emb_val.repeat(1, 3, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.network.fc = nn.Linear(in_features=model.network.fc.in_features, out_features=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_fit(model.network, emb_train_225, labels_trains['train_size_225'].values, emb_val, labels_val.values, steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.network(torch.tensor(emb_val).float()).detach().numpy()\n",
    "\n",
    "# plot histogram of scores for positive and negative clips\n",
    "plt.hist(preds[labels_val==True],bins=20,alpha=0.5,label='positives')\n",
    "plt.hist(preds[labels_val==False],bins=20,alpha=0.5,label='negatives')\n",
    "plt.legend()\n",
    "\n",
    "# calculate the area under the ROC score\n",
    "roc_auc_score_225 = roc_auc_score(labels_val.values,preds,average=None)\n",
    "roc_auc_score_225"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training size 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.hub.load('kitzeslab/bioacoustics-model-zoo','rana_sierrae_cnn',trust_repo=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_train_250 = model.embed(labels_trains['train_size_250'], return_dfs=False, batch_size=32, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_val = model.embed(labels_val, return_dfs=False, batch_size=32, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_train_250 = torch.tensor(emb_train_250, dtype=torch.float32)\n",
    "emb_val = torch.tensor(emb_val, dtype=torch.float32)\n",
    "\n",
    "# Check the shape of the embeddings\n",
    "print(f\"Original shape of emb_train: {emb_train_250.shape}\")\n",
    "\n",
    "# Reshape embeddings to [batch_size, channels, height, width]\n",
    "height, width = 32, 16  # Ensure height * width = 512\n",
    "emb_train_250 = emb_train_250.view(emb_train_250.shape[0], 1, height, width)\n",
    "emb_val = emb_val.view(emb_val.shape[0], 1, height, width)\n",
    "\n",
    "# Verify the reshaped embeddings\n",
    "print(f\"Reshaped emb_train_250: {emb_train_250.shape}\")\n",
    "print(f\"Reshaped emb_val: {emb_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(model.network, nn.Sequential):\n",
    "    first_layer = model.network[0]\n",
    "    if isinstance(first_layer, nn.Conv2d):\n",
    "        model.network[0] = nn.Conv2d(\n",
    "            in_channels=1,\n",
    "            out_channels=first_layer.out_channels,\n",
    "            kernel_size=first_layer.kernel_size,\n",
    "            stride=first_layer.stride,\n",
    "            padding=first_layer.padding\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_train_250 = emb_train_250.repeat(1, 3, 1, 1) \n",
    "emb_val = emb_val.repeat(1, 3, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.network.fc = nn.Linear(in_features=model.network.fc.in_features, out_features=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_fit(model.network, emb_train_250, labels_trains['train_size_250'].values, emb_val, labels_val.values, steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.network(torch.tensor(emb_val).float()).detach().numpy()\n",
    "\n",
    "# plot histogram of scores for positive and negative clips\n",
    "plt.hist(preds[labels_val==True],bins=20,alpha=0.5,label='positives')\n",
    "plt.hist(preds[labels_val==False],bins=20,alpha=0.5,label='negatives')\n",
    "plt.legend()\n",
    "\n",
    "# calculate the area under the ROC score\n",
    "roc_auc_score_250 = roc_auc_score(labels_val.values,preds,average=None)\n",
    "roc_auc_score_250"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training size 275"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.hub.load('kitzeslab/bioacoustics-model-zoo','rana_sierrae_cnn',trust_repo=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_train_275 = model.embed(labels_trains['train_size_275'], return_dfs=False, batch_size=32, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_val = model.embed(labels_val, return_dfs=False, batch_size=32, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_train_275 = torch.tensor(emb_train_275, dtype=torch.float32)\n",
    "emb_val = torch.tensor(emb_val, dtype=torch.float32)\n",
    "# Check the shape of the embeddings\n",
    "print(f\"Original shape of emb_train: {emb_train_275.shape}\")\n",
    "\n",
    "# Reshape embeddings to [batch_size, channels, height, width]\n",
    "height, width = 32, 16  # Ensure height * width = 512\n",
    "emb_train_275 = emb_train_275.view(emb_train_275.shape[0], 1, height, width)\n",
    "emb_val = emb_val.view(emb_val.shape[0], 1, height, width)\n",
    "\n",
    "# Verify the reshaped embeddings\n",
    "print(f\"Reshaped emb_train_275: {emb_train_275.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(model.network, nn.Sequential):\n",
    "    first_layer = model.network[0]\n",
    "    if isinstance(first_layer, nn.Conv2d):\n",
    "        model.network[0] = nn.Conv2d(\n",
    "            in_channels=1,\n",
    "            out_channels=first_layer.out_channels,\n",
    "            kernel_size=first_layer.kernel_size,\n",
    "            stride=first_layer.stride,\n",
    "            padding=first_layer.padding\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_train_275 = emb_train_275.repeat(1, 3, 1, 1) \n",
    "emb_val = emb_val.repeat(1, 3, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.network.fc = nn.Linear(in_features=model.network.fc.in_features, out_features=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_fit(model.network, emb_train_275, labels_trains['train_size_275'].values, emb_val, labels_val.values, steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.network(torch.tensor(emb_val).float()).detach().numpy()\n",
    "\n",
    "# plot histogram of scores for positive and negative clips\n",
    "plt.hist(preds[labels_val==True],bins=20,alpha=0.5,label='positives')\n",
    "plt.hist(preds[labels_val==False],bins=20,alpha=0.5,label='negatives')\n",
    "plt.legend()\n",
    "\n",
    "# calculate the area under the ROC score\n",
    "roc_auc_score_275 = roc_auc_score(labels_val.values,preds,average=None)\n",
    "roc_auc_score_275"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training size 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.hub.load('kitzeslab/bioacoustics-model-zoo','rana_sierrae_cnn',trust_repo=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_train_300 = model.embed(labels_trains['train_size_300'], return_dfs=False, batch_size=32, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_val = model.embed(labels_val, return_dfs=False, batch_size=32, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_train_300 = torch.tensor(emb_train_300, dtype=torch.float32)\n",
    "emb_val = torch.tensor(emb_val, dtype=torch.float32)\n",
    "# Check the shape of the embeddings\n",
    "print(f\"Original shape of emb_train: {emb_train_300.shape}\")\n",
    "\n",
    "# Reshape embeddings to [batch_size, channels, height, width]\n",
    "height, width = 32, 16  # Ensure height * width = 512\n",
    "emb_train_300 = emb_train_300.view(emb_train_300.shape[0], 1, height, width)\n",
    "emb_val = emb_val.view(emb_val.shape[0], 1, height, width)\n",
    "\n",
    "# Verify the reshaped embeddings\n",
    "print(f\"Reshaped emb_train_300: {emb_train_300.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(model.network, nn.Sequential):\n",
    "    first_layer = model.network[0]\n",
    "    if isinstance(first_layer, nn.Conv2d):\n",
    "        model.network[0] = nn.Conv2d(\n",
    "            in_channels=1,\n",
    "            out_channels=first_layer.out_channels,\n",
    "            kernel_size=first_layer.kernel_size,\n",
    "            stride=first_layer.stride,\n",
    "            padding=first_layer.padding\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_val = emb_val.repeat(1, 3, 1, 1)\n",
    "emb_train_300 = emb_train_300.repeat(1, 3, 1, 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.network.fc = nn.Linear(in_features=model.network.fc.in_features, out_features=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_fit(model.network, emb_train_300, labels_trains['train_size_300'].values, emb_val, labels_val.values, steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.network(torch.tensor(emb_val).float()).detach().numpy()\n",
    "\n",
    "# plot histogram of scores for positive and negative clips\n",
    "plt.hist(preds[labels_val==True],bins=20,alpha=0.5,label='positives')\n",
    "plt.hist(preds[labels_val==False],bins=20,alpha=0.5,label='negatives')\n",
    "plt.legend()\n",
    "\n",
    "# calculate the area under the ROC score\n",
    "roc_auc_score_300 = roc_auc_score(labels_val.values,preds,average=None)\n",
    "roc_auc_score_300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_sizes = []\n",
    "roc_auc_scores = []\n",
    "\n",
    "# Iterate over training sizes and collect the scores\n",
    "for size in range(25, 301, 25):\n",
    "    score = eval(f\"roc_auc_score_{size}\")\n",
    "    training_sizes.append(size)\n",
    "    roc_auc_scores.append(score)\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\"Training Size\": training_sizes, \"ROC AUC Score\": roc_auc_scores})\n",
    "\n",
    "\n",
    "# Plot a line plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(df[\"Training Size\"], df[\"ROC AUC Score\"], marker='o', linestyle='-')\n",
    "plt.title(\"ROC AUC Score vs. Training Size\")\n",
    "plt.xlabel(\"Training Size\")\n",
    "plt.ylabel(\"ROC AUC Score\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opensoundscape_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
