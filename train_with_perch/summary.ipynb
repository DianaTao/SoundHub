{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{25: 0.9511111111111111,\n",
       " 50: 0.9480888888888889,\n",
       " 75: 0.9415111111111111,\n",
       " 100: 0.9411555555555556,\n",
       " 125: 0.9715555555555556,\n",
       " 150: 0.9511111111111111,\n",
       " 175: 0.9612444444444445,\n",
       " 200: 0.9678222222222223,\n",
       " 225: 0.9480888888888889,\n",
       " 250: 0.9749333333333332,\n",
       " 275: 0.9616,\n",
       " 300: 0.948088888888889}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_size_to_score_bullfrog = {}\n",
    "bullfrog_score =  [0.9511111111111111, 0.9480888888888889, 0.9415111111111111, 0.9411555555555556, 0.9715555555555556, 0.9511111111111111, 0.9612444444444445, 0.9678222222222223, 0.9480888888888889, 0.9749333333333332, 0.9616,0.948088888888889]\n",
    "\n",
    "j = 0\n",
    "for i in range(25, 301, 25):\n",
    "    training_size_to_score_bullfrog[i] = bullfrog_score[j]\n",
    "    j += 1\n",
    "\n",
    "training_size_to_score_bullfrog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{25: 0.9468000000000001,\n",
       " 50: 0.9808,\n",
       " 75: 0.9716,\n",
       " 100: 0.9724,\n",
       " 125: 0.9904,\n",
       " 150: 0.9803999999999999,\n",
       " 175: 0.9787999999999999,\n",
       " 200: 0.9768}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_size_to_score_coyote = {}\n",
    "coyote_score = [0.9468000000000001, 0.9808, 0.9716, 0.9724, 0.9904, 0.9803999999999999, 0.9787999999999999, 0.9768]\n",
    "\n",
    "j = 0\n",
    "for i in range(25, 201, 25):\n",
    "    training_size_to_score_coyote[i] = coyote_score[j]\n",
    "    j += 1\n",
    "\n",
    "training_size_to_score_coyote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{25: 0.8400000000000001, 50: 0.8479999999999999, 75: 0.824, 100: 0.8896}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_size_to_score_engine = {}\n",
    "engine_score = [0.8400000000000001, 0.8479999999999999, 0.824, 0.8896]\n",
    "j = 0\n",
    "for i in range(25, 101, 25):\n",
    "    training_size_to_score_engine[i] = engine_score[j]\n",
    "    j += 1\n",
    "\n",
    "training_size_to_score_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{25: 0.8622222222222222, 50: 0.8933333333333333, 60: 0.8977777777777778}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_size_to_score_human_vocal = {}\n",
    "human_vocal = [0.8622222222222222, 0.8933333333333333, 0.8977777777777778]\n",
    "training_size_to_score_human_vocal[25] = human_vocal[0]\n",
    "training_size_to_score_human_vocal[50] = human_vocal[1]\n",
    "training_size_to_score_human_vocal[60] = human_vocal[2]\n",
    "training_size_to_score_human_vocal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{25: 0.9921777777777778,\n",
       " 50: 0.9994666666666667,\n",
       " 75: 1.0,\n",
       " 100: 1.0,\n",
       " 125: 1.0,\n",
       " 150: 0.9975111111111111,\n",
       " 175: 1.0,\n",
       " 200: 0.9811555555555556,\n",
       " 225: 1.0,\n",
       " 250: 1.0,\n",
       " 275: 1.0,\n",
       " 300: 0.9991111111111112}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_size_to_score_WT = {}\n",
    "woodhouses_toad_score = [0.9921777777777778, 0.9994666666666667, 1.0, 1.0, 1.0, 0.9975111111111111, 1.0, 0.9811555555555556, 1.0, 1.0,1.0, 0.9991111111111112]\n",
    "len(woodhouses_toad_score)\n",
    "j = 0\n",
    "for i in range(25, 301, 25):\n",
    "    training_size_to_score_WT[i] = woodhouses_toad_score[j]\n",
    "    j += 1\n",
    "\n",
    "training_size_to_score_WT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{25: 0.5640888888888889,\n",
       " 50: 0.5662222222222222,\n",
       " 75: 0.6042666666666666,\n",
       " 100: 0.5447111111111111,\n",
       " 125: 0.5992888888888889,\n",
       " 150: 0.5685333333333333,\n",
       " 175: 0.5532444444444444,\n",
       " 200: 0.5564444444444444,\n",
       " 225: 0.5504,\n",
       " 250: 0.5534222222222223,\n",
       " 275: 0.5223111111111112,\n",
       " 300: 0.5221333333333333}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_size_to_score_pcf = {}\n",
    "pcf_score = [0.5640888888888889, 0.5662222222222222, 0.6042666666666666, 0.5447111111111111, 0.5992888888888889, 0.5685333333333333, 0.5532444444444444, 0.5564444444444444, 0.5504 ,0.5534222222222223 ,0.5223111111111112, 0.5221333333333333]\n",
    "j = 0\n",
    "for i in range(25, 301, 25):\n",
    "    training_size_to_score_pcf[i] = pcf_score[j]\n",
    "    j += 1\n",
    "\n",
    "training_size_to_score_pcf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{25: 0.850864,\n",
       " 50: 0.796543,\n",
       " 75: 0.807407,\n",
       " 100: 0.815802,\n",
       " 125: 0.777778,\n",
       " 150: 0.83358}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_size_to_score_field_cricket = {}\n",
    "field_cricket_score= [0.850864, 0.796543, 0.807407, 0.815802, 0.777778, 0.833580]\n",
    "j = 0\n",
    "for i in range(25, 151, 25):\n",
    "    training_size_to_score_field_cricket[i] = field_cricket_score[j]\n",
    "    j += 1\n",
    "\n",
    "training_size_to_score_field_cricket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"coyote\": training_size_to_score_coyote,\n",
    "        \"bullfrog\":training_size_to_score_bullfrog,\n",
    "        \"pacific chorus frog\": training_size_to_score_pcf,\n",
    "        \"woodhouses toad\" : training_size_to_score_WT,\n",
    "        \"field_cricket\" : training_size_to_score_field_cricket,\n",
    "        \"human vocal\" : training_size_to_score_human_vocal,\n",
    "        \"engine\" : training_size_to_score_engine}\n",
    "df = pd.DataFrame(data)\n",
    "csv_path = '/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/summary_data.csv'\n",
    "df.to_csv(csv_path, index_label='Training Size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coyote</th>\n",
       "      <th>bullfrog</th>\n",
       "      <th>pacific chorus frog</th>\n",
       "      <th>woodhouses toad</th>\n",
       "      <th>field_cricket</th>\n",
       "      <th>human vocal</th>\n",
       "      <th>engine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.974750</td>\n",
       "      <td>0.955526</td>\n",
       "      <td>0.558756</td>\n",
       "      <td>0.997452</td>\n",
       "      <td>0.813662</td>\n",
       "      <td>0.884444</td>\n",
       "      <td>0.850400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.012709</td>\n",
       "      <td>0.011530</td>\n",
       "      <td>0.025036</td>\n",
       "      <td>0.005606</td>\n",
       "      <td>0.026097</td>\n",
       "      <td>0.019373</td>\n",
       "      <td>0.027973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.946800</td>\n",
       "      <td>0.941156</td>\n",
       "      <td>0.522133</td>\n",
       "      <td>0.981156</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.862222</td>\n",
       "      <td>0.824000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.972200</td>\n",
       "      <td>0.948089</td>\n",
       "      <td>0.548978</td>\n",
       "      <td>0.998711</td>\n",
       "      <td>0.799259</td>\n",
       "      <td>0.877778</td>\n",
       "      <td>0.836000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.977800</td>\n",
       "      <td>0.951111</td>\n",
       "      <td>0.554933</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.811605</td>\n",
       "      <td>0.893333</td>\n",
       "      <td>0.844000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.980500</td>\n",
       "      <td>0.963156</td>\n",
       "      <td>0.566800</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.829136</td>\n",
       "      <td>0.895556</td>\n",
       "      <td>0.858400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.990400</td>\n",
       "      <td>0.974933</td>\n",
       "      <td>0.604267</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.850864</td>\n",
       "      <td>0.897778</td>\n",
       "      <td>0.889600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         coyote   bullfrog  pacific chorus frog  woodhouses toad  \\\n",
       "count  8.000000  12.000000            12.000000        12.000000   \n",
       "mean   0.974750   0.955526             0.558756         0.997452   \n",
       "std    0.012709   0.011530             0.025036         0.005606   \n",
       "min    0.946800   0.941156             0.522133         0.981156   \n",
       "25%    0.972200   0.948089             0.548978         0.998711   \n",
       "50%    0.977800   0.951111             0.554933         1.000000   \n",
       "75%    0.980500   0.963156             0.566800         1.000000   \n",
       "max    0.990400   0.974933             0.604267         1.000000   \n",
       "\n",
       "       field_cricket  human vocal    engine  \n",
       "count       6.000000     3.000000  4.000000  \n",
       "mean        0.813662     0.884444  0.850400  \n",
       "std         0.026097     0.019373  0.027973  \n",
       "min         0.777778     0.862222  0.824000  \n",
       "25%         0.799259     0.877778  0.836000  \n",
       "50%         0.811605     0.893333  0.844000  \n",
       "75%         0.829136     0.895556  0.858400  \n",
       "max         0.850864     0.897778  0.889600  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_stats = df.describe()\n",
    "summary_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training results of the Google PERCH model indicate strong performance across multiple categories. The \"coyote\" category achieved an average accuracy of 97.5% with low variability (std = 1.3%), while \"bullfrog\" had an average of 95.6% with slightly higher variability (std = 1.2%). The \"pacific chorus frog\" showed moderate performance, averaging 55.9% accuracy, with variability indicating slight instability (std = 2.5%). \"Woodhouse's toad\" performed exceptionally, averaging 99.7% accuracy with minimal variability (std = 0.6%). Other categories, such as \"field cricket,\" averaged 81.4% with some fluctuations (std = 2.6%), and \"human vocal\" scored 88.4% with limited data available. Finally, the \"engine\" category averaged 85.0%, with moderate variability (std = 2.8%). These results suggest the model is highly accurate for certain categories, while others, such as \"pacific chorus frog,\" may benefit from further refinement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the training size increased, most categories demonstrated improved performance, suggesting that the model effectively learned better feature representations with larger datasets. However, the extent of this improvement varied significantly among categories, reflecting differences in the complexity of the underlying features and the sufficiency of the data.\n",
    "\n",
    "For high-performing categories like Coyote and Woodhouse's Toad, the model reached excellent accuracy levels even with smaller training sizes. For instance, the Coyote category achieved 94.7% accuracy with a training size of 25 and stabilized at over 97% as the dataset grew. Similarly, Woodhouse's Toad demonstrated near-perfect performance early on, with 98.1% accuracy at a training size of 25 and 100% accuracy by size 75. These results suggest that the model quickly identified and leveraged the distinct features of these categories, making additional data unnecessary for further improvement. This early stabilization highlights the efficiency of the model in learning simpler or more distinguishable features.\n",
    "\n",
    "On the other hand, categories like Pacific Chorus Frog and Field Cricket presented challenges, even with larger training sizes. The Pacific Chorus Frog category started at 52.2% accuracy with 25 training samples and improved to 60.4% by size 75, but its performance dipped slightly at higher training sizes, suggesting the need for better data representation or additional feature engineering. Field Cricket showed moderate accuracy improvements, ranging from 77.8% to 85.1%, but variability across training sizes indicated instability in the learning process. These findings suggest that these categories either have more complex features or suffer from insufficient or imbalanced data, necessitating targeted interventions to enhance their performance.\n",
    "\n",
    "Limited observations for the Human Vocal and Engine categories constrained detailed analysis, but a general upward trend was evident for Engine accuracy as training size increased, ranging from 82.4% to 88.9%. Human Vocal averaged 88.4% accuracy, demonstrating good baseline performance, but additional data points are required to assess its full learning potential. These trends underscore the importance of sufficient training data to stabilize and optimize model performance, particularly for underrepresented classes.\n",
    "\n",
    "In conclusion, while the model performs exceptionally well for categories like Woodhouse's Toad and Bullfrog with minimal training data, categories such as Pacific Chorus Frog and Field Cricket require additional focus to improve accuracy and stability. Strategies such as reallocating training resources, augmenting data, and rebalancing classes could help address performance disparities. Moreover, analyzing feature quality for underperforming categories might uncover specific challenges in their representations, guiding targeted improvements. Understanding these dynamics allows for optimizing training processes and enhancing the overall performance of the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opensoundscape_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
