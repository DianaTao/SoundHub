{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/3533495058.py:10: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random \n",
    "from glob import glob\n",
    "import sklearn\n",
    "\n",
    "from tqdm.autonotebook import tqdm\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score\n",
    "from pathlib import Path\n",
    "\n",
    "#set up plotting\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['figure.figsize']=[15,5] #for large visuals\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# opensoundscape transfer learning tools\n",
    "from opensoundscape.ml.shallow_classifier import MLPClassifier, quick_fit, fit_classifier_on_embeddings\n",
    "import os\n",
    "from pathlib import Path\n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "random.seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved for training size train_size_150: /Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/labels_trains_train_size_150.csv\n",
      "DataFrame saved for training size train_size_25: /Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/labels_trains_train_size_25.csv\n",
      "DataFrame saved for training size train_size_300: /Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/labels_trains_train_size_300.csv\n",
      "DataFrame saved for training size train_size_275: /Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/labels_trains_train_size_275.csv\n",
      "DataFrame saved for training size train_size_250: /Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/labels_trains_train_size_250.csv\n",
      "DataFrame saved for training size train_size_175: /Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/labels_trains_train_size_175.csv\n",
      "DataFrame saved for training size train_size_75: /Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/labels_trains_train_size_75.csv\n",
      "DataFrame saved for training size train_size_100: /Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/labels_trains_train_size_100.csv\n",
      "DataFrame saved for training size train_size_225: /Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/labels_trains_train_size_225.csv\n",
      "DataFrame saved for training size train_size_200: /Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/labels_trains_train_size_200.csv\n",
      "DataFrame saved for training size train_size_50: /Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/labels_trains_train_size_50.csv\n",
      "DataFrame saved for training size train_size_125: /Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/labels_trains_train_size_125.csv\n",
      "\n",
      "DataFrame for training size train_size_150:\n",
      "                                                                        A\n",
      "file                                               start_time end_time   \n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "\n",
      "DataFrame for training size train_size_25:\n",
      "                                                                        A\n",
      "file                                               start_time end_time   \n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "\n",
      "DataFrame for training size train_size_300:\n",
      "                                                                        A\n",
      "file                                               start_time end_time   \n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "\n",
      "DataFrame for training size train_size_275:\n",
      "                                                                        A\n",
      "file                                               start_time end_time   \n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "\n",
      "DataFrame for training size train_size_250:\n",
      "                                                                        A\n",
      "file                                               start_time end_time   \n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "\n",
      "DataFrame for training size train_size_175:\n",
      "                                                                        A\n",
      "file                                               start_time end_time   \n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "\n",
      "DataFrame for training size train_size_75:\n",
      "                                                                        A\n",
      "file                                               start_time end_time   \n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "\n",
      "DataFrame for training size train_size_100:\n",
      "                                                                        A\n",
      "file                                               start_time end_time   \n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "\n",
      "DataFrame for training size train_size_225:\n",
      "                                                                        A\n",
      "file                                               start_time end_time   \n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "\n",
      "DataFrame for training size train_size_200:\n",
      "                                                                        A\n",
      "file                                               start_time end_time   \n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "\n",
      "DataFrame for training size train_size_50:\n",
      "                                                                        A\n",
      "file                                               start_time end_time   \n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "\n",
      "DataFrame for training size train_size_125:\n",
      "                                                                        A\n",
      "file                                               start_time end_time   \n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
      "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Define dataset path\n",
    "dataset_path = Path(\"/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/\")\n",
    "train_path = dataset_path / \"train_5sec\"\n",
    "\n",
    "# Function to traverse directories and map file information to labels\n",
    "def traverse_and_map(directory, label):\n",
    "    audio_files = []\n",
    "    labels = []\n",
    "    start_times = []\n",
    "    end_times = []\n",
    "    \n",
    "    if not directory.exists():\n",
    "        print(f\"Directory does not exist: {directory}\")\n",
    "        return pd.DataFrame()  # Return empty DataFrame if directory doesn't exist\n",
    "    \n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith(\".wav\"):\n",
    "                # Prepend full dataset path to the file path\n",
    "                audio_path = dataset_path / Path(root).relative_to(dataset_path) / file\n",
    "                audio_files.append(str(audio_path))\n",
    "                labels.append(label)\n",
    "                start_times.append(0.0)  # Fixed start time\n",
    "                end_times.append(5.0)   # Fixed end time\n",
    "\n",
    "    # Create DataFrame for the current directory\n",
    "    data = {\n",
    "        \"file\": audio_files,\n",
    "        \"start_time\": start_times,\n",
    "        \"end_time\": end_times,\n",
    "        \"A\": labels\n",
    "    }\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Initialize a dictionary to hold DataFrames for each training size\n",
    "labels_trains = {}\n",
    "\n",
    "# Iterate over each train size folder\n",
    "if train_path.exists():\n",
    "    for train_size_dir in train_path.iterdir():\n",
    "        if train_size_dir.is_dir():  # Ensure it's a directory\n",
    "            training_size = train_size_dir.name  # Get the name of the training size directory\n",
    "\n",
    "            # Process `pos` and `neg` subdirectories\n",
    "            pos_dir = train_size_dir / \"pos\"\n",
    "            neg_dir = train_size_dir / \"neg\"\n",
    "            df_pos = traverse_and_map(pos_dir, 1)  # 1 for \"pos\" files\n",
    "            df_neg = traverse_and_map(neg_dir, 0)  # 0 for \"negative\" files\n",
    "\n",
    "            # Combine the DataFrames for `pos` and `neg`\n",
    "            combined_df = pd.concat([df_pos, df_neg], ignore_index=True)\n",
    "\n",
    "            # Set MultiIndex with 'file', 'start_time', and 'end_time'\n",
    "            combined_df.set_index([\"file\", \"start_time\", \"end_time\"], inplace=True)\n",
    "\n",
    "            # Rename the only column to \"A\"\n",
    "            combined_df.columns = ['A']\n",
    "\n",
    "            # Store the DataFrame in the dictionary\n",
    "            labels_trains[training_size] = combined_df\n",
    "\n",
    "            # Optionally, save each DataFrame to a CSV file\n",
    "            output_path = dataset_path / f\"labels_trains_{training_size}.csv\"\n",
    "            combined_df.to_csv(output_path)\n",
    "            print(f\"DataFrame saved for training size {training_size}: {output_path}\")\n",
    "else:\n",
    "    print(f\"Train path does not exist: {train_path}\")\n",
    "\n",
    "# Display the DataFrames for verification\n",
    "for training_size, df in labels_trains.items():\n",
    "    print(f\"\\nDataFrame for training size {training_size}:\")\n",
    "    print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing data for training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>file</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/train_5sec/train_size_150/pos/t-11127057_285.wav</th>\n",
       "      <th>0.0</th>\n",
       "      <th>5.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/train_5sec/train_size_150/pos/t-11127057_520.wav</th>\n",
       "      <th>0.0</th>\n",
       "      <th>5.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/train_5sec/train_size_150/pos/t-11127057_65.wav</th>\n",
       "      <th>0.0</th>\n",
       "      <th>5.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/train_5sec/train_size_150/pos/t-11127057_71.wav</th>\n",
       "      <th>0.0</th>\n",
       "      <th>5.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/train_5sec/train_size_150/pos/t-11127057_722.wav</th>\n",
       "      <th>0.0</th>\n",
       "      <th>5.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/train_5sec/train_size_150/pos/t-11127057_656.wav</th>\n",
       "      <th>0.0</th>\n",
       "      <th>5.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/train_5sec/train_size_150/pos/t-11127057_118.wav</th>\n",
       "      <th>0.0</th>\n",
       "      <th>5.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/train_5sec/train_size_150/pos/t-11127057_497.wav</th>\n",
       "      <th>0.0</th>\n",
       "      <th>5.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/train_5sec/train_size_150/pos/t-11127057_440.wav</th>\n",
       "      <th>0.0</th>\n",
       "      <th>5.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/train_5sec/train_size_150/pos/t-11127057_247.wav</th>\n",
       "      <th>0.0</th>\n",
       "      <th>5.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/train_5sec/train_size_150/pos/t-11127057_521.wav</th>\n",
       "      <th>0.0</th>\n",
       "      <th>5.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/train_5sec/train_size_150/pos/t-11127057_286.wav</th>\n",
       "      <th>0.0</th>\n",
       "      <th>5.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/train_5sec/train_size_150/pos/t-11127057_251.wav</th>\n",
       "      <th>0.0</th>\n",
       "      <th>5.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/train_5sec/train_size_150/pos/t-11127057_669.wav</th>\n",
       "      <th>0.0</th>\n",
       "      <th>5.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/train_5sec/train_size_150/pos/t-11127057_494.wav</th>\n",
       "      <th>0.0</th>\n",
       "      <th>5.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/train_5sec/train_size_150/pos/t-11127057_443.wav</th>\n",
       "      <th>0.0</th>\n",
       "      <th>5.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/train_5sec/train_size_150/pos/t-11127057_319.wav</th>\n",
       "      <th>0.0</th>\n",
       "      <th>5.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/train_5sec/train_size_150/pos/t-11127057_7.wav</th>\n",
       "      <th>0.0</th>\n",
       "      <th>5.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/train_5sec/train_size_150/pos/t-11127057_683.wav</th>\n",
       "      <th>0.0</th>\n",
       "      <th>5.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/train_5sec/train_size_150/pos/t-11127057_697.wav</th>\n",
       "      <th>0.0</th>\n",
       "      <th>5.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                        A\n",
       "file                                               start_time end_time   \n",
       "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
       "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
       "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
       "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
       "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
       "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
       "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
       "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
       "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
       "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
       "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
       "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
       "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
       "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
       "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
       "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
       "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
       "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
       "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1\n",
       "/Users/yifeitao/Desktop/SoundHub/SoundHub/train... 0.0        5.0       1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_trains['train_size_150'].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare audio Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Train shallow classifier on Perch embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/yifeitao/.cache/torch/hub/kitzeslab_bioacoustics-model-zoo_main\n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('kitzeslab/bioacoustics-model-zoo','rana_sierrae_cnn',trust_repo=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Generate embeddings on the training and validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training size 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "063fc5c75fd041499e8b7a712b05e93d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.999833333333333 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n"
     ]
    }
   ],
   "source": [
    "emb_train_25 = model.embed(labels_trains['train_size_25'], return_dfs=False, batch_size=32, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:20: ResourceWarning: unclosed file <_io.BufferedReader name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/test_dataset_5sec.wav'>\n",
      "  audio = AudioSegment.from_file(audio_file_path)\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11127057_34.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11127057_755.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11113588_399.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11113588_513.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11113588_90.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11127057_79.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11127057_233.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11113588_78.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11127057_358.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11113588_441.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11113588_17.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11127057_645.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11127057_671.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11127057_636.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11127057_660.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11127057_316.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11113588_480.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11127057_88.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11127057_369.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11031961_289_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11127057_783.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11031961_331_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11127057_262.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11031961_100_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11113588_258.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11113588_388.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11113588_23.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11113588_757.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11127057_525.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11127057_217.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11127057_632.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11127057_396.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11127057_549.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11127057_287.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11127057_176.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11113588_781.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11127057_111.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11127057_348.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11127057_67.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11127057_544.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11113588_443.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11031961_272_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11113588_60.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11127057_246.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11127057_66.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11031961_288_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11113588_398.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11031961_280_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11113588_97.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11113588_42.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11113588_509.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11113588_779.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11127057_50.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11127057_703.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11113588_380.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11127057_569.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11127057_600.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11127057_141.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11127057_595.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11127057_492.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11031961_270_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11127057_647.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11127057_31.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11127057_728.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11113588_472.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11127057_304.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11113588_113.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11113588_133.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11127057_434.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11113588_543.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11113588_468.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11127057_650.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11113588_769.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11113588_125.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11127057_663.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11113588_516.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11031961_325_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11127057_591.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11127057_761.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11031961_321_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11113588_28.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11127057_446.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11127057_24.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11113588_454.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11031961_306_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11127057_40.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11113588_489.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11127057_695.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11127057_696.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11127057_545.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11127057_602.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11113588_406.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11031961_263_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11113588_479.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11113588_8.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11031961_262_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11127057_556.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11127057_68.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11113588_767.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11113588_482.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11127057_533.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11127057_641.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11127057_804.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11127057_803.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11113588_548.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11127057_384.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11031961_254_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11113588_57.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11127057_64.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11127057_467.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11127057_337.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11031961_269_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11127057_267.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11113588_762.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11127057_424.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11113588_567.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11127057_475.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11113588_556.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11113588_38.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11127057_170.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11031961_298_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11127057_252.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11127057_200.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11031961_329_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11127057_682.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11113588_451.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11031961_316_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11113588_382.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11127057_534.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11127057_765.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11113588_530.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11113588_100.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11127057_311.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11127057_807.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11127057_674.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11127057_788.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11113588_542.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11113588_106.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11113588_404.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11113588_122.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11113588_136.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11127057_32.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11113588_132.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11113588_474.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11127057_407.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11127057_194.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11113588_507.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11127057_328.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11113588_478.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n",
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/873706465.py:40: ResourceWarning: unclosed file <_io.BufferedRandom name='/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips/t-11031961_268_9sec_1_a.wav'>\n",
      "  clip.export(clip_path, format=\"wav\")\n"
     ]
    }
   ],
   "source": [
    "csv_path = Path(\"/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/test_dataset_5sec.csv\")\n",
    "audio_file_path = Path(\"/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/test_dataset_5sec.wav\")\n",
    "output_folder = Path(\"/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/clips\")\n",
    "output_csv_dir = Path(\"/Users/yifeitao/Desktop/SoundHub/SoundHub/train_with_perch/pacific_chorus_frog_5sec/test_5sec/\")\n",
    "output_csv = output_csv_dir / \"processed_test_dataset_5sec.csv\"\n",
    "\n",
    "# Ensure the output directories exist\n",
    "output_folder.mkdir(parents=True, exist_ok=True)\n",
    "output_csv_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Read the CSV file\n",
    "df_csv = pd.read_csv(csv_path)\n",
    "\n",
    "# Determine label based on conditions\n",
    "df_csv[\"A\"] = df_csv.apply(\n",
    "    lambda row: 1 if row[\"label\"] == 1 and row[\"Annotation\"] == \"PCF\" else 0, axis=1\n",
    ")\n",
    "\n",
    "# Load the audio file\n",
    "audio = AudioSegment.from_file(audio_file_path)\n",
    "\n",
    "# Initialize lists for DataFrame creation\n",
    "file_paths = []\n",
    "start_times = []\n",
    "end_times = []\n",
    "labels = []\n",
    "\n",
    "# Partition the audio file into 5-second clips based on CSV\n",
    "for index, row in df_csv.iterrows():\n",
    "    start_time = index * 5 * 1000  # in milliseconds\n",
    "    end_time = start_time + 5 * 1000  # 5 seconds later\n",
    "\n",
    "    # Extract clip\n",
    "    clip = audio[start_time:end_time]\n",
    "\n",
    "    # Save clip to the output folder\n",
    "    #WT does not have unique row identifier filename column\n",
    "    filename = row[\"filename\"]\n",
    "    clip_path = output_folder / filename\n",
    "    clip.export(clip_path, format=\"wav\")\n",
    "\n",
    "    # Add details to lists\n",
    "    file_paths.append(str(clip_path))\n",
    "    start_times.append(0.0)  \n",
    "    end_times.append(5.0)  \n",
    "    labels.append(row[\"A\"])\n",
    "\n",
    "# Create the DataFrame\n",
    "df_processed = pd.DataFrame({\n",
    "    \"file\": file_paths,\n",
    "    \"start_time\": start_times,\n",
    "    \"end_time\": end_times,\n",
    "    \"A\": labels\n",
    "})\n",
    "df_processed.set_index([\"file\", \"start_time\", \"end_time\"], inplace=True)\n",
    "df_processed.columns = ['A']\n",
    "# Save the DataFrame to a CSV file\n",
    "df_processed.to_csv(output_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_val = df_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d7fa906c8374419a167d0c56abca319",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1725: UserWarning: Audio object is shorter than requested duration: 4.975 sec instead of 5.0 sec\n",
      "  warnings.warn(error_msg)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/audio.py:1713: UserWarning: audio object has zero samples\n",
      "  warnings.warn(error_msg)\n"
     ]
    }
   ],
   "source": [
    "emb_val = model.embed(labels_val, return_dfs=False, batch_size=32, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape of emb_train: torch.Size([50, 512])\n",
      "Reshaped emb_train_25: torch.Size([50, 1, 32, 16])\n",
      "Reshaped emb_val: torch.Size([150, 1, 32, 16])\n"
     ]
    }
   ],
   "source": [
    "emb_train_25 = torch.tensor(emb_train_25, dtype=torch.float32)\n",
    "emb_val = torch.tensor(emb_val, dtype=torch.float32)\n",
    "\n",
    "# Check the shape of the embeddings\n",
    "print(f\"Original shape of emb_train: {emb_train_25.shape}\")\n",
    "\n",
    "# Reshape embeddings to [batch_size, channels, height, width]\n",
    "height, width = 32, 16  # Ensure height * width = 512\n",
    "emb_train_25 = emb_train_25.view(emb_train_25.shape[0], 1, height, width)\n",
    "emb_val = emb_val.view(emb_val.shape[0], 1, height, width)\n",
    "\n",
    "# Verify the reshaped embeddings\n",
    "print(f\"Reshaped emb_train_25: {emb_train_25.shape}\")\n",
    "print(f\"Reshaped emb_val: {emb_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "if isinstance(model.network, nn.Sequential):\n",
    "    first_layer = model.network[0]\n",
    "    if isinstance(first_layer, nn.Conv2d):\n",
    "        model.network[0] = nn.Conv2d(\n",
    "            in_channels=1,\n",
    "            out_channels=first_layer.out_channels,\n",
    "            kernel_size=first_layer.kernel_size,\n",
    "            stride=first_layer.stride,\n",
    "            padding=first_layer.padding\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_train_25 = emb_train_25.repeat(1, 3, 1, 1)  # Duplicate to 3 channels\n",
    "emb_val = emb_val.repeat(1, 3, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "model.network.fc = nn.Linear(in_features=model.network.fc.in_features, out_features=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mask for NaN values\n",
    "nan_mask = torch.isnan(emb_val)\n",
    "\n",
    "# Replace NaN values with 0\n",
    "emb_val[nan_mask] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/ml/shallow_classifier.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_features = torch.tensor(train_features, dtype=torch.float32, device=device)\n",
      "/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/ml/shallow_classifier.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  validation_features = torch.tensor(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/1000, Loss: 3.117222877335735e-05, Val Loss: nan\n",
      "val AU ROC: nan\n",
      "val MAP: nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mquick_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnetwork\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memb_train_25\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels_trains\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain_size_25\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memb_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels_val\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/opensoundscape/ml/shallow_classifier.py:126\u001b[0m, in \u001b[0;36mquick_fit\u001b[0;34m(model, train_features, train_labels, validation_features, validation_labels, steps, optimizer, criterion, device)\u001b[0m\n\u001b[1;32m    123\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m    124\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 126\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, train_labels)\n\u001b[1;32m    129\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/torchvision/models/resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/torchvision/models/resnet.py:268\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_forward_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;66;03m# See note [TorchScript super()]\u001b[39;00m\n\u001b[0;32m--> 268\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    269\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(x)\n\u001b[1;32m    270\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(x)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/torch/nn/modules/conv.py:554\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/opensoundscape_env/lib/python3.9/site-packages/torch/nn/modules/conv.py:549\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[1;32m    539\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m    540\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    548\u001b[0m     )\n\u001b[0;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "quick_fit(model.network, emb_train_25, labels_trains['train_size_25'].values, emb_val, labels_val.values, steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v4/chwhws6x79ncg51bwr5778b00000gn/T/ipykernel_4790/1842857064.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  preds = model.network(torch.tensor(emb_val).float()).detach().numpy()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5640888888888889"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 428,
       "width": 1209
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make predictions by passing the embeddings through the classifier\n",
    "preds = model.network(torch.tensor(emb_val).float()).detach().numpy()\n",
    "\n",
    "# plot histogram of scores for positive and negative clips\n",
    "plt.hist(preds[labels_val==True],bins=20,alpha=0.5,label='positives')\n",
    "plt.hist(preds[labels_val==False],bins=20,alpha=0.5,label='negatives')\n",
    "plt.legend()\n",
    "\n",
    "# calculate the area under the ROC score\n",
    "roc_auc_score_25 = roc_auc_score(labels_val.values,preds,average=None)\n",
    "roc_auc_score_25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training size 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_train_50 = model.embed(labels_trains['train_size_50'], return_dfs=False, batch_size=32, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_train_50 = torch.tensor(emb_train_50, dtype=torch.float32)\n",
    "\n",
    "# Check the shape of the embeddings\n",
    "print(f\"Original shape of emb_train: {emb_train_50.shape}\")\n",
    "\n",
    "# Reshape embeddings to [batch_size, channels, height, width]\n",
    "height, width = 32, 16  # Ensure height * width = 512\n",
    "emb_train_50 = emb_train_50.view(emb_train_50.shape[0], 1, height, width)\n",
    "\n",
    "# Verify the reshaped embeddings\n",
    "print(f\"Reshaped emb_train_50: {emb_train_50.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_train_50 = emb_train_50.repeat(1, 3, 1, 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_fit(model.network, emb_train_50, labels_trains['train_size_50'].values, emb_val, labels_val.values, steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions by passing the embeddings through the classifier\n",
    "preds = model.network(torch.tensor(emb_val).float()).detach().numpy()\n",
    "\n",
    "# plot histogram of scores for positive and negative clips\n",
    "plt.hist(preds[labels_val==True],bins=20,alpha=0.5,label='positives')\n",
    "plt.hist(preds[labels_val==False],bins=20,alpha=0.5,label='negatives')\n",
    "plt.legend()\n",
    "\n",
    "# calculate the area under the ROC score\n",
    "roc_auc_score_50 = roc_auc_score(labels_val.values,preds,average=None)\n",
    "roc_auc_score_50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training size 75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_train_75 = model.embed(labels_trains['train_size_75'], return_dfs=False, batch_size=32, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_train_75 = torch.tensor(emb_train_75, dtype=torch.float32)\n",
    "\n",
    "# Check the shape of the embeddings\n",
    "print(f\"Original shape of emb_train: {emb_train_75.shape}\")\n",
    "\n",
    "# Reshape embeddings to [batch_size, channels, height, width]\n",
    "height, width = 32, 16  # Ensure height * width = 512\n",
    "emb_train_75 = emb_train_75.view(emb_train_75.shape[0], 1, height, width)\n",
    "\n",
    "\n",
    "# Verify the reshaped embeddings\n",
    "print(f\"Reshaped emb_train_75: {emb_train_75.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_train_75 = emb_train_75.repeat(1, 3, 1, 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_fit(model.network, emb_train_75, labels_trains['train_size_75'].values, emb_val, labels_val.values, steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions by passing the embeddings through the classifier\n",
    "preds = model.network(torch.tensor(emb_val).float()).detach().numpy()\n",
    "\n",
    "# plot histogram of scores for positive and negative clips\n",
    "plt.hist(preds[labels_val==True],bins=20,alpha=0.5,label='positives')\n",
    "plt.hist(preds[labels_val==False],bins=20,alpha=0.5,label='negatives')\n",
    "plt.legend()\n",
    "\n",
    "# calculate the area under the ROC score\n",
    "roc_auc_score_75 = roc_auc_score(labels_val.values,preds,average=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training size 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_train_100 = model.embed(labels_trains['train_size_100'], return_dfs=False, batch_size=32, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_train_100 = torch.tensor(emb_train_100, dtype=torch.float32)\n",
    "# Check the shape of the embeddings\n",
    "print(f\"Original shape of emb_train: {emb_train_100.shape}\")\n",
    "\n",
    "# Reshape embeddings to [batch_size, channels, height, width]\n",
    "height, width = 32, 16  # Ensure height * width = 512\n",
    "emb_train_100 = emb_train_100.view(emb_train_100.shape[0], 1, height, width)\n",
    "\n",
    "# Verify the reshaped embeddings\n",
    "print(f\"Reshaped emb_train_100: {emb_train_100.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_train_100 = emb_train_100.repeat(1, 3, 1, 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_fit(model.network, emb_train_100, labels_trains['train_size_100'].values, emb_val, labels_val.values, steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions by passing the embeddings through the classifier\n",
    "preds = model.network(torch.tensor(emb_val).float()).detach().numpy()\n",
    "\n",
    "# plot histogram of scores for positive and negative clips\n",
    "plt.hist(preds[labels_val==True],bins=20,alpha=0.5,label='positives')\n",
    "plt.hist(preds[labels_val==False],bins=20,alpha=0.5,label='negatives')\n",
    "plt.legend()\n",
    "\n",
    "# calculate the area under the ROC score\n",
    "roc_auc_score_100 = roc_auc_score(labels_val.values,preds,average=None)\n",
    "roc_auc_score_100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training size 125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_train_125 = model.embed(labels_trains['train_size_125'], return_dfs=False, batch_size=32, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_train_125 = torch.tensor(emb_train_125, dtype=torch.float32)\n",
    "# Check the shape of the embeddings\n",
    "print(f\"Original shape of emb_train: {emb_train_125.shape}\")\n",
    "\n",
    "height, width = 32, 16  # Ensure height * width = 512\n",
    "emb_train_125 = emb_train_125.view(emb_train_125.shape[0], 1, height, width)\n",
    "\n",
    "# Verify the reshaped embeddings\n",
    "print(f\"Reshaped emb_train_100: {emb_train_125.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_train_125 = emb_train_125.repeat(1, 3, 1, 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_fit(model.network, emb_train_125, labels_trains['train_size_125'].values, emb_val, labels_val.values, steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions by passing the embeddings through the classifier\n",
    "preds = model.network(torch.tensor(emb_val).float()).detach().numpy()\n",
    "\n",
    "# plot histogram of scores for positive and negative clips\n",
    "plt.hist(preds[labels_val==True],bins=20,alpha=0.5,label='positives')\n",
    "plt.hist(preds[labels_val==False],bins=20,alpha=0.5,label='negatives')\n",
    "plt.legend()\n",
    "\n",
    "# calculate the area under the ROC score\n",
    "roc_auc_score_125 = roc_auc_score(labels_val.values,preds,average=None)\n",
    "roc_auc_score_125"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training size 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_train_150 = model.embed(labels_trains['train_size_150'], return_dfs=False, batch_size=32, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_train_150 = torch.tensor(emb_train_150, dtype=torch.float32)\n",
    "# Check the shape of the embeddings\n",
    "print(f\"Original shape of emb_train: {emb_train_150.shape}\")\n",
    "\n",
    "# Reshape embeddings to [batch_size, channels, height, width]\n",
    "height, width = 32, 16  # Ensure height * width = 512\n",
    "emb_train_150 = emb_train_150.view(emb_train_150.shape[0], 1, height, width)\n",
    "\n",
    "# Verify the reshaped embeddings\n",
    "print(f\"Reshaped emb_train_150: {emb_train_150.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_train_150 = emb_train_150.repeat(1, 3, 1, 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_fit(model.network, emb_train_150, labels_trains['train_size_150'].values, emb_val, labels_val.values, steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions by passing the embeddings through the classifier\n",
    "preds = model.network(torch.tensor(emb_val).float()).detach().numpy()\n",
    "\n",
    "# plot histogram of scores for positive and negative clips\n",
    "plt.hist(preds[labels_val==True],bins=20,alpha=0.5,label='positives')\n",
    "plt.hist(preds[labels_val==False],bins=20,alpha=0.5,label='negatives')\n",
    "plt.legend()\n",
    "\n",
    "# calculate the area under the ROC score\n",
    "roc_auc_score_150 = roc_auc_score(labels_val.values,preds,average=None)\n",
    "roc_auc_score_150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training size 175"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_train_175 = model.embed(labels_trains['train_size_175'], return_dfs=False, batch_size=32, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_train_175 = torch.tensor(emb_train_175, dtype=torch.float32)\n",
    "# Check the shape of the embeddings\n",
    "print(f\"Original shape of emb_train: {emb_train_175.shape}\")\n",
    "\n",
    "# Reshape embeddings to [batch_size, channels, height, width]\n",
    "height, width = 32, 16  # Ensure height * width = 512\n",
    "emb_train_175 = emb_train_175.view(emb_train_175.shape[0], 1, height, width)\n",
    "\n",
    "\n",
    "# Verify the reshaped embeddings\n",
    "print(f\"Reshaped emb_train_175: {emb_train_175.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_train_175 = emb_train_175.repeat(1, 3, 1, 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_fit(model.network, emb_train_175, labels_trains['train_size_175'].values, emb_val, labels_val.values, steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.network(torch.tensor(emb_val).float()).detach().numpy()\n",
    "\n",
    "# plot histogram of scores for positive and negative clips\n",
    "plt.hist(preds[labels_val==True],bins=20,alpha=0.5,label='positives')\n",
    "plt.hist(preds[labels_val==False],bins=20,alpha=0.5,label='negatives')\n",
    "plt.legend()\n",
    "\n",
    "# calculate the area under the ROC score\n",
    "roc_auc_score_175 = roc_auc_score(labels_val.values,preds,average=None)\n",
    "roc_auc_score_175"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training size 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.hub.load('kitzeslab/bioacoustics-model-zoo','rana_sierrae_cnn',trust_repo=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_val = model.embed(labels_val, return_dfs=False, batch_size=32, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_train_200 = model.embed(labels_trains['train_size_200'], return_dfs=False, batch_size=32, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_train_200 = torch.tensor(emb_train_200, dtype=torch.float32)\n",
    "emb_val = torch.tensor(emb_val, dtype=torch.float32)\n",
    "\n",
    "# Check the shape of the embeddings\n",
    "print(f\"Original shape of emb_train: {emb_train_200.shape}\")\n",
    "\n",
    "# Reshape embeddings to [batch_size, channels, height, width]\n",
    "height, width = 32, 16  # Ensure height * width = 512\n",
    "emb_train_200 = emb_train_200.view(emb_train_200.shape[0], 1, height, width)\n",
    "emb_val = emb_val.view(emb_val.shape[0], 1, height, width)\n",
    "\n",
    "# Verify the reshaped embeddings\n",
    "print(f\"Reshaped emb_train_200: {emb_train_200.shape}\")\n",
    "print(f\"Reshaped emb_val: {emb_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(model.network, nn.Sequential):\n",
    "    first_layer = model.network[0]\n",
    "    if isinstance(first_layer, nn.Conv2d):\n",
    "        model.network[0] = nn.Conv2d(\n",
    "            in_channels=1,\n",
    "            out_channels=first_layer.out_channels,\n",
    "            kernel_size=first_layer.kernel_size,\n",
    "            stride=first_layer.stride,\n",
    "            padding=first_layer.padding\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_train_200 = emb_train_200.repeat(1, 3, 1, 1) \n",
    "emb_val = emb_val.repeat(1, 3, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.network.fc = nn.Linear(in_features=model.network.fc.in_features, out_features=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_fit(model.network, emb_train_200, labels_trains['train_size_200'].values, emb_val, labels_val.values, steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.network(torch.tensor(emb_val).float()).detach().numpy()\n",
    "\n",
    "# plot histogram of scores for positive and negative clips\n",
    "plt.hist(preds[labels_val==True],bins=20,alpha=0.5,label='positives')\n",
    "plt.hist(preds[labels_val==False],bins=20,alpha=0.5,label='negatives')\n",
    "plt.legend()\n",
    "\n",
    "# calculate the area under the ROC score\n",
    "roc_auc_score_200 = roc_auc_score(labels_val.values,preds,average=None)\n",
    "roc_auc_score_200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training size 225"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.hub.load('kitzeslab/bioacoustics-model-zoo','rana_sierrae_cnn',trust_repo=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_val = model.embed(labels_val, return_dfs=False, batch_size=32, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_train_225 = model.embed(labels_trains['train_size_225'], return_dfs=False, batch_size=32, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_train_225 = torch.tensor(emb_train_225, dtype=torch.float32)\n",
    "emb_val = torch.tensor(emb_val, dtype=torch.float32)\n",
    "\n",
    "# Check the shape of the embeddings\n",
    "print(f\"Original shape of emb_train: {emb_train_225.shape}\")\n",
    "\n",
    "# Reshape embeddings to [batch_size, channels, height, width]\n",
    "height, width = 32, 16  # Ensure height * width = 512\n",
    "emb_train_225 = emb_train_225.view(emb_train_225.shape[0], 1, height, width)\n",
    "emb_val = emb_val.view(emb_val.shape[0], 1, height, width)\n",
    "\n",
    "# Verify the reshaped embeddings\n",
    "print(f\"Reshaped emb_train_225: {emb_train_225.shape}\")\n",
    "print(f\"Reshaped emb_val: {emb_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(model.network, nn.Sequential):\n",
    "    first_layer = model.network[0]\n",
    "    if isinstance(first_layer, nn.Conv2d):\n",
    "        model.network[0] = nn.Conv2d(\n",
    "            in_channels=1,\n",
    "            out_channels=first_layer.out_channels,\n",
    "            kernel_size=first_layer.kernel_size,\n",
    "            stride=first_layer.stride,\n",
    "            padding=first_layer.padding\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_train_225 = emb_train_225.repeat(1, 3, 1, 1) \n",
    "emb_val = emb_val.repeat(1, 3, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.network.fc = nn.Linear(in_features=model.network.fc.in_features, out_features=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_fit(model.network, emb_train_225, labels_trains['train_size_225'].values, emb_val, labels_val.values, steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.network(torch.tensor(emb_val).float()).detach().numpy()\n",
    "\n",
    "# plot histogram of scores for positive and negative clips\n",
    "plt.hist(preds[labels_val==True],bins=20,alpha=0.5,label='positives')\n",
    "plt.hist(preds[labels_val==False],bins=20,alpha=0.5,label='negatives')\n",
    "plt.legend()\n",
    "\n",
    "# calculate the area under the ROC score\n",
    "roc_auc_score_225 = roc_auc_score(labels_val.values,preds,average=None)\n",
    "roc_auc_score_225"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training size 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.hub.load('kitzeslab/bioacoustics-model-zoo','rana_sierrae_cnn',trust_repo=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_train_250 = model.embed(labels_trains['train_size_250'], return_dfs=False, batch_size=32, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_val = model.embed(labels_val, return_dfs=False, batch_size=32, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_train_250 = torch.tensor(emb_train_250, dtype=torch.float32)\n",
    "emb_val = torch.tensor(emb_val, dtype=torch.float32)\n",
    "\n",
    "# Check the shape of the embeddings\n",
    "print(f\"Original shape of emb_train: {emb_train_250.shape}\")\n",
    "\n",
    "# Reshape embeddings to [batch_size, channels, height, width]\n",
    "height, width = 32, 16  # Ensure height * width = 512\n",
    "emb_train_250 = emb_train_250.view(emb_train_250.shape[0], 1, height, width)\n",
    "emb_val = emb_val.view(emb_val.shape[0], 1, height, width)\n",
    "\n",
    "# Verify the reshaped embeddings\n",
    "print(f\"Reshaped emb_train_250: {emb_train_250.shape}\")\n",
    "print(f\"Reshaped emb_val: {emb_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(model.network, nn.Sequential):\n",
    "    first_layer = model.network[0]\n",
    "    if isinstance(first_layer, nn.Conv2d):\n",
    "        model.network[0] = nn.Conv2d(\n",
    "            in_channels=1,\n",
    "            out_channels=first_layer.out_channels,\n",
    "            kernel_size=first_layer.kernel_size,\n",
    "            stride=first_layer.stride,\n",
    "            padding=first_layer.padding\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_train_250 = emb_train_250.repeat(1, 3, 1, 1) \n",
    "emb_val = emb_val.repeat(1, 3, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.network.fc = nn.Linear(in_features=model.network.fc.in_features, out_features=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_fit(model.network, emb_train_250, labels_trains['train_size_250'].values, emb_val, labels_val.values, steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.network(torch.tensor(emb_val).float()).detach().numpy()\n",
    "\n",
    "# plot histogram of scores for positive and negative clips\n",
    "plt.hist(preds[labels_val==True],bins=20,alpha=0.5,label='positives')\n",
    "plt.hist(preds[labels_val==False],bins=20,alpha=0.5,label='negatives')\n",
    "plt.legend()\n",
    "\n",
    "# calculate the area under the ROC score\n",
    "roc_auc_score_250 = roc_auc_score(labels_val.values,preds,average=None)\n",
    "roc_auc_score_250"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training size 275"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.hub.load('kitzeslab/bioacoustics-model-zoo','rana_sierrae_cnn',trust_repo=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_train_275 = model.embed(labels_trains['train_size_275'], return_dfs=False, batch_size=32, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_val = model.embed(labels_val, return_dfs=False, batch_size=32, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_train_275 = torch.tensor(emb_train_275, dtype=torch.float32)\n",
    "emb_val = torch.tensor(emb_val, dtype=torch.float32)\n",
    "# Check the shape of the embeddings\n",
    "print(f\"Original shape of emb_train: {emb_train_275.shape}\")\n",
    "\n",
    "# Reshape embeddings to [batch_size, channels, height, width]\n",
    "height, width = 32, 16  # Ensure height * width = 512\n",
    "emb_train_275 = emb_train_275.view(emb_train_275.shape[0], 1, height, width)\n",
    "emb_val = emb_val.view(emb_val.shape[0], 1, height, width)\n",
    "\n",
    "# Verify the reshaped embeddings\n",
    "print(f\"Reshaped emb_train_275: {emb_train_275.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(model.network, nn.Sequential):\n",
    "    first_layer = model.network[0]\n",
    "    if isinstance(first_layer, nn.Conv2d):\n",
    "        model.network[0] = nn.Conv2d(\n",
    "            in_channels=1,\n",
    "            out_channels=first_layer.out_channels,\n",
    "            kernel_size=first_layer.kernel_size,\n",
    "            stride=first_layer.stride,\n",
    "            padding=first_layer.padding\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_train_275 = emb_train_275.repeat(1, 3, 1, 1) \n",
    "emb_val = emb_val.repeat(1, 3, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.network.fc = nn.Linear(in_features=model.network.fc.in_features, out_features=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_fit(model.network, emb_train_275, labels_trains['train_size_275'].values, emb_val, labels_val.values, steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.network(torch.tensor(emb_val).float()).detach().numpy()\n",
    "\n",
    "# plot histogram of scores for positive and negative clips\n",
    "plt.hist(preds[labels_val==True],bins=20,alpha=0.5,label='positives')\n",
    "plt.hist(preds[labels_val==False],bins=20,alpha=0.5,label='negatives')\n",
    "plt.legend()\n",
    "\n",
    "# calculate the area under the ROC score\n",
    "roc_auc_score_275 = roc_auc_score(labels_val.values,preds,average=None)\n",
    "roc_auc_score_275"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training size 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.hub.load('kitzeslab/bioacoustics-model-zoo','rana_sierrae_cnn',trust_repo=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_train_300 = model.embed(labels_trains['train_size_300'], return_dfs=False, batch_size=32, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_val = model.embed(labels_val, return_dfs=False, batch_size=32, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_train_300 = torch.tensor(emb_train_300, dtype=torch.float32)\n",
    "emb_val = torch.tensor(emb_val, dtype=torch.float32)\n",
    "# Check the shape of the embeddings\n",
    "print(f\"Original shape of emb_train: {emb_train_300.shape}\")\n",
    "\n",
    "# Reshape embeddings to [batch_size, channels, height, width]\n",
    "height, width = 32, 16  # Ensure height * width = 512\n",
    "emb_train_300 = emb_train_300.view(emb_train_300.shape[0], 1, height, width)\n",
    "emb_val = emb_val.view(emb_val.shape[0], 1, height, width)\n",
    "\n",
    "# Verify the reshaped embeddings\n",
    "print(f\"Reshaped emb_train_300: {emb_train_300.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(model.network, nn.Sequential):\n",
    "    first_layer = model.network[0]\n",
    "    if isinstance(first_layer, nn.Conv2d):\n",
    "        model.network[0] = nn.Conv2d(\n",
    "            in_channels=1,\n",
    "            out_channels=first_layer.out_channels,\n",
    "            kernel_size=first_layer.kernel_size,\n",
    "            stride=first_layer.stride,\n",
    "            padding=first_layer.padding\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_val = emb_val.repeat(1, 3, 1, 1)\n",
    "emb_train_300 = emb_train_300.repeat(1, 3, 1, 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.network.fc = nn.Linear(in_features=model.network.fc.in_features, out_features=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_fit(model.network, emb_train_300, labels_trains['train_size_300'].values, emb_val, labels_val.values, steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.network(torch.tensor(emb_val).float()).detach().numpy()\n",
    "\n",
    "# plot histogram of scores for positive and negative clips\n",
    "plt.hist(preds[labels_val==True],bins=20,alpha=0.5,label='positives')\n",
    "plt.hist(preds[labels_val==False],bins=20,alpha=0.5,label='negatives')\n",
    "plt.legend()\n",
    "\n",
    "# calculate the area under the ROC score\n",
    "roc_auc_score_300 = roc_auc_score(labels_val.values,preds,average=None)\n",
    "roc_auc_score_300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_sizes = []\n",
    "roc_auc_scores = []\n",
    "\n",
    "# Iterate over training sizes and collect the scores\n",
    "for size in range(25, 301, 25):\n",
    "    score = eval(f\"roc_auc_score_{size}\")\n",
    "    training_sizes.append(size)\n",
    "    roc_auc_scores.append(score)\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\"Training Size\": training_sizes, \"ROC AUC Score\": roc_auc_scores})\n",
    "\n",
    "\n",
    "# Plot a line plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(df[\"Training Size\"], df[\"ROC AUC Score\"], marker='o', linestyle='-')\n",
    "plt.title(\"ROC AUC Score vs. Training Size\")\n",
    "plt.xlabel(\"Training Size\")\n",
    "plt.ylabel(\"ROC AUC Score\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opensoundscape_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
